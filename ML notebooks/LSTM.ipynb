{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "icuHFdJW3DLB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import psycopg2\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.decomposition import PCA\n",
        "import statsmodels.api as sm\n",
        "import configparser\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Activation\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.callbacks import History\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BnFlfRne_cgp"
      },
      "outputs": [],
      "source": [
        "def fetch_data():\n",
        "    config = configparser.ConfigParser()\n",
        "    config.read('db_config.ini')\n",
        "\n",
        "    host = config['database']['host']\n",
        "    port = config['database'].getint('port')\n",
        "    user = config['database']['user']\n",
        "    password = config['database']['password']\n",
        "    database = config['database']['database']\n",
        "\n",
        "    connection = psycopg2.connect(\n",
        "        host=host,\n",
        "        port=port,\n",
        "        user=user,\n",
        "        password=password,\n",
        "        database=database\n",
        "    )\n",
        "\n",
        "    df1 = pd.read_sql('SELECT * FROM turbofan_engine_data', con=connection)\n",
        "    df2 = pd.read_sql('SELECT * FROM turbofan_rul_data', con=connection)\n",
        "\n",
        "    connection.close()\n",
        "\n",
        "    return df1, df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FIckfxROTnDs"
      },
      "outputs": [],
      "source": [
        "df1, df2 = fetch_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gb8HE1KuCVlK"
      },
      "outputs": [],
      "source": [
        "def clean_data(df):\n",
        "    # Handling missing values\n",
        "    na_counts_before = df.isna().sum()\n",
        "    if na_counts_before.sum() > 0:\n",
        "        print(f\"Rows with missing values before: {na_counts_before.sum()}\")\n",
        "        df = df.dropna(axis=0)\n",
        "        na_counts_after = df.isna().sum()\n",
        "        print(f\"Rows with missing values after: {na_counts_after.sum()}\")\n",
        "    else:\n",
        "        print(\"No missing values found. Proceeding with the original DataFrame.\")\n",
        "\n",
        "    # Handling duplicates\n",
        "    duplicates_before = df[df.duplicated(keep='first')]\n",
        "    if len(duplicates_before) > 0:\n",
        "        print(f\"Duplicates before: {len(duplicates_before)}\")\n",
        "        df = df.drop_duplicates(keep='first')\n",
        "        duplicates_after = df[df.duplicated(keep='first')]\n",
        "        print(f\"Duplicates after: {len(duplicates_after)}\")\n",
        "    else:\n",
        "        print(\"No duplicate rows found. Proceeding with the original DataFrame.\")\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o25imog1CY1i",
        "outputId": "f1bd0d87-68e5-4e25-dd6e-69e27db98833"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No missing values found. Proceeding with the original DataFrame.\n",
            "No duplicate rows found. Proceeding with the original DataFrame.\n",
            "No missing values found. Proceeding with the original DataFrame.\n",
            "No duplicate rows found. Proceeding with the original DataFrame.\n"
          ]
        }
      ],
      "source": [
        "df1 = clean_data(df1)\n",
        "df2 = clean_data(df2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oY7MWkSgCbcz"
      },
      "outputs": [],
      "source": [
        "train_df = df1[df1[\"source\"] == 0].copy()\n",
        "test_df = df1[df1[\"source\"] == 1].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7qC958YTsZ1"
      },
      "source": [
        "# **Deriving RUL Column**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vgIeLozsL0KP"
      },
      "outputs": [],
      "source": [
        "def add_rul_train(df):\n",
        "    max_cycles_train = df.groupby('engine')['cycle'].max().reset_index()\n",
        "    max_cycles_train.columns = ['engine', 'max_cycle_train']\n",
        "    df = df.merge(max_cycles_train, on='engine', how='left')\n",
        "    df['RUL'] = df['max_cycle_train'] - df['cycle']\n",
        "    df.drop(['max_cycle_train'], axis=1, inplace=True)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PDuWxRZoXzUM"
      },
      "outputs": [],
      "source": [
        "train_df_with_rul = add_rul_train(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2ZL2ZBTqMJUh"
      },
      "outputs": [],
      "source": [
        "df_train = train_df_with_rul.copy()\n",
        "df_test = test_df\n",
        "y_true = df2.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARODLGqIMP2M",
        "outputId": "90c9376d-ccfb-4ce5-9624-db85ed8bd492"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((53759, 29), (33991, 28), (259, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df_train.shape, df_test.shape, y_true.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "w0A2j1lvXU_5"
      },
      "outputs": [],
      "source": [
        "features = df_train.columns.drop(['index','source','engine', 'cycle', 'RUL'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fTxplP5DXYHU"
      },
      "outputs": [],
      "source": [
        "sc = MinMaxScaler(feature_range=(-1,1))\n",
        "\n",
        "df_train[features] = sc.fit_transform(df_train[features])\n",
        "df_test[features] = sc.transform(df_test[features])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJU9kBNEWCSn"
      },
      "source": [
        "# **Preparing Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nuZOo0F7XbgL"
      },
      "outputs": [],
      "source": [
        "#function to prepare train data into (samples, time steps, features)\n",
        "\n",
        "def gen_train(id_df, seq_length, seq_cols):\n",
        "\n",
        "    data_array = id_df[seq_cols].values\n",
        "    num_elements = data_array.shape[0]\n",
        "    lstm_array=[]\n",
        "\n",
        "    for start, stop in zip(range(0, num_elements-seq_length+1), range(seq_length, num_elements+1)):\n",
        "        lstm_array.append(data_array[start:stop, :])\n",
        "\n",
        "    return np.array(lstm_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Acg6tdrFXeA3"
      },
      "outputs": [],
      "source": [
        "def gen_target(id_df, seq_length, label):\n",
        "    data_array = id_df[label].values\n",
        "    num_elements = data_array.shape[0]\n",
        "    return data_array[seq_length-1:num_elements+1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "I7uzeD4fXgcv"
      },
      "outputs": [],
      "source": [
        "# Function to prepare test data into (samples, time steps, features).\n",
        "\n",
        "def gen_test(id_df, seq_length, seq_cols, mask_value):\n",
        "\n",
        "    df_mask = pd.DataFrame(np.zeros((seq_length-1, id_df.shape[1])), columns=id_df.columns)\n",
        "    df_mask[:] = mask_value\n",
        "\n",
        "    id_df = pd.concat([df_mask, id_df], ignore_index=True)\n",
        "\n",
        "    data_array = id_df[seq_cols].values\n",
        "    num_elements = data_array.shape[0]\n",
        "    lstm_array = []\n",
        "\n",
        "    start = num_elements - seq_length\n",
        "    stop = num_elements\n",
        "\n",
        "    lstm_array.append(data_array[start:stop, :])\n",
        "\n",
        "    return np.array(lstm_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ZyTNeP7-XjGy"
      },
      "outputs": [],
      "source": [
        "sequence_length = 50\n",
        "mask_value = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwfjkEnMXlPZ",
        "outputId": "7536968d-c0af-4845-fb4f-523bbbe074da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(41019, 50, 24)\n"
          ]
        }
      ],
      "source": [
        "x_train=np.concatenate(list(list(gen_train(df_train[df_train['engine']==unit], sequence_length, features)) for unit in df_train['engine'].unique()))\n",
        "print(x_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfo0zFaUXl2K",
        "outputId": "cebbb44e-fb2b-432d-ca9c-6b60b159084e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(41019,)\n"
          ]
        }
      ],
      "source": [
        "y_train = np.concatenate(list(list(gen_target(df_train[df_train['engine']==unit], sequence_length, \"RUL\")) for unit in df_train['engine'].unique()))\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYhMfvA5Xppo",
        "outputId": "61599cfa-946b-4649-a1d7-4741ab0101df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(259, 50, 24)\n"
          ]
        }
      ],
      "source": [
        "x_test=np.concatenate(list(list(gen_test(df_test[df_test['engine']==unit], sequence_length, features, mask_value)) for unit in df_test['engine'].unique()))\n",
        "print(x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5MUGQD8Xtu9",
        "outputId": "bfd8eae0-bbbb-43fc-a346-569dad8abf4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(259,)\n"
          ]
        }
      ],
      "source": [
        "y_test = y_true.RUL.values\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "umSzNw5-Xx7A"
      },
      "outputs": [],
      "source": [
        "nb_features = x_train.shape[2]\n",
        "nb_out = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tTKs1ilX1P0",
        "outputId": "936904fd-2894-4950-d22c-371f8dad0bec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "nb_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwhKnDZGWHIo"
      },
      "source": [
        "# **Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "RqRZlBc7YAZX"
      },
      "outputs": [],
      "source": [
        "history = History()\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(\n",
        "         units=100,\n",
        "         return_sequences=True,\n",
        "         input_shape=(sequence_length, nb_features)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(\n",
        "          units=100,\n",
        "          return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(\n",
        "          units=100,\n",
        "          return_sequences=False))\n",
        "model.add(Dense(units=50, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=1, activation='relu'))\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=\"rmsprop\", metrics=['mse'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRIL907jYFKe",
        "outputId": "9b6b1896-34e4-4717-951d-3ec9b5f5c056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "289/289 [==============================] - 124s 403ms/step - loss: 4142.7979 - mse: 4142.7979 - val_loss: 4206.7656 - val_mse: 4206.7656\n",
            "Epoch 2/100\n",
            "289/289 [==============================] - 116s 401ms/step - loss: 2295.8374 - mse: 2295.8374 - val_loss: 1850.7705 - val_mse: 1850.7705\n",
            "Epoch 3/100\n",
            "289/289 [==============================] - 113s 391ms/step - loss: 1621.9384 - mse: 1621.9384 - val_loss: 1970.2701 - val_mse: 1970.2701\n",
            "Epoch 4/100\n",
            "289/289 [==============================] - 119s 411ms/step - loss: 1453.2338 - mse: 1453.2338 - val_loss: 1775.2072 - val_mse: 1775.2072\n",
            "Epoch 5/100\n",
            "289/289 [==============================] - 117s 404ms/step - loss: 1319.7524 - mse: 1319.7524 - val_loss: 1492.0029 - val_mse: 1492.0029\n",
            "Epoch 6/100\n",
            "289/289 [==============================] - 114s 394ms/step - loss: 1246.2896 - mse: 1246.2896 - val_loss: 2209.3464 - val_mse: 2209.3464\n",
            "Epoch 7/100\n",
            "289/289 [==============================] - 115s 397ms/step - loss: 1195.9802 - mse: 1195.9802 - val_loss: 1962.2396 - val_mse: 1962.2396\n",
            "Epoch 8/100\n",
            "289/289 [==============================] - 120s 415ms/step - loss: 1129.0354 - mse: 1129.0354 - val_loss: 2208.7422 - val_mse: 2208.7422\n",
            "Epoch 9/100\n",
            "289/289 [==============================] - 113s 390ms/step - loss: 1069.5323 - mse: 1069.5323 - val_loss: 1545.7828 - val_mse: 1545.7828\n",
            "Epoch 10/100\n",
            "289/289 [==============================] - 112s 387ms/step - loss: 982.7815 - mse: 982.7815 - val_loss: 1593.3168 - val_mse: 1593.3168\n",
            "Epoch 11/100\n",
            "289/289 [==============================] - 112s 387ms/step - loss: 892.8769 - mse: 892.8769 - val_loss: 1630.6952 - val_mse: 1630.6952\n",
            "Epoch 12/100\n",
            "289/289 [==============================] - 113s 392ms/step - loss: 769.4929 - mse: 769.4929 - val_loss: 1495.2892 - val_mse: 1495.2892\n",
            "Epoch 13/100\n",
            "289/289 [==============================] - 113s 391ms/step - loss: 655.2975 - mse: 655.2975 - val_loss: 1800.8049 - val_mse: 1800.8049\n",
            "Epoch 14/100\n",
            "289/289 [==============================] - 115s 399ms/step - loss: 563.9655 - mse: 563.9655 - val_loss: 1676.1808 - val_mse: 1676.1808\n",
            "Epoch 15/100\n",
            "289/289 [==============================] - 114s 395ms/step - loss: 489.8490 - mse: 489.8490 - val_loss: 1530.8707 - val_mse: 1530.8707\n",
            "Epoch 16/100\n",
            "289/289 [==============================] - 115s 398ms/step - loss: 429.5778 - mse: 429.5778 - val_loss: 1460.7717 - val_mse: 1460.7717\n",
            "Epoch 17/100\n",
            "289/289 [==============================] - 116s 403ms/step - loss: 381.5575 - mse: 381.5575 - val_loss: 1361.7446 - val_mse: 1361.7446\n",
            "Epoch 18/100\n",
            "289/289 [==============================] - 117s 405ms/step - loss: 338.8854 - mse: 338.8854 - val_loss: 1930.6753 - val_mse: 1930.6753\n",
            "Epoch 19/100\n",
            "289/289 [==============================] - 120s 414ms/step - loss: 309.8246 - mse: 309.8246 - val_loss: 1954.3030 - val_mse: 1954.3030\n",
            "Epoch 20/100\n",
            "289/289 [==============================] - 117s 406ms/step - loss: 271.6935 - mse: 271.6935 - val_loss: 1867.0441 - val_mse: 1867.0441\n",
            "Epoch 21/100\n",
            "289/289 [==============================] - 115s 397ms/step - loss: 260.3354 - mse: 260.3354 - val_loss: 1995.3040 - val_mse: 1995.3040\n",
            "Epoch 22/100\n",
            "289/289 [==============================] - 120s 413ms/step - loss: 241.1475 - mse: 241.1475 - val_loss: 1787.9127 - val_mse: 1787.9127\n",
            "Epoch 23/100\n",
            "289/289 [==============================] - 116s 403ms/step - loss: 226.3088 - mse: 226.3088 - val_loss: 2048.4973 - val_mse: 2048.4973\n",
            "Epoch 24/100\n",
            "289/289 [==============================] - 123s 427ms/step - loss: 215.4588 - mse: 215.4588 - val_loss: 1944.8578 - val_mse: 1944.8578\n",
            "Epoch 25/100\n",
            "289/289 [==============================] - 117s 404ms/step - loss: 206.1060 - mse: 206.1060 - val_loss: 2026.4988 - val_mse: 2026.4988\n",
            "Epoch 26/100\n",
            "289/289 [==============================] - 121s 418ms/step - loss: 194.2652 - mse: 194.2652 - val_loss: 1976.8375 - val_mse: 1976.8375\n",
            "Epoch 27/100\n",
            "289/289 [==============================] - 113s 390ms/step - loss: 187.3576 - mse: 187.3576 - val_loss: 2183.3237 - val_mse: 2183.3237\n",
            "Epoch 28/100\n",
            "289/289 [==============================] - 114s 396ms/step - loss: 185.4663 - mse: 185.4663 - val_loss: 1684.1509 - val_mse: 1684.1509\n",
            "Epoch 29/100\n",
            "289/289 [==============================] - 113s 391ms/step - loss: 174.4290 - mse: 174.4290 - val_loss: 1876.6265 - val_mse: 1876.6265\n",
            "Epoch 30/100\n",
            "289/289 [==============================] - 113s 390ms/step - loss: 168.4351 - mse: 168.4351 - val_loss: 1780.7032 - val_mse: 1780.7032\n",
            "Epoch 31/100\n",
            "289/289 [==============================] - 117s 404ms/step - loss: 163.6189 - mse: 163.6189 - val_loss: 1938.0547 - val_mse: 1938.0547\n",
            "Epoch 32/100\n",
            "289/289 [==============================] - 121s 417ms/step - loss: 155.9957 - mse: 155.9957 - val_loss: 1951.1439 - val_mse: 1951.1439\n",
            "Epoch 33/100\n",
            "289/289 [==============================] - 114s 395ms/step - loss: 153.3654 - mse: 153.3654 - val_loss: 1822.6278 - val_mse: 1822.6278\n",
            "Epoch 34/100\n",
            "289/289 [==============================] - 115s 397ms/step - loss: 150.4216 - mse: 150.4216 - val_loss: 1965.9550 - val_mse: 1965.9550\n",
            "Epoch 35/100\n",
            "289/289 [==============================] - 118s 408ms/step - loss: 145.9578 - mse: 145.9578 - val_loss: 1996.7600 - val_mse: 1996.7600\n",
            "Epoch 36/100\n",
            "289/289 [==============================] - 114s 394ms/step - loss: 141.3860 - mse: 141.3860 - val_loss: 2122.3223 - val_mse: 2122.3223\n",
            "Epoch 37/100\n",
            "289/289 [==============================] - 115s 398ms/step - loss: 141.8371 - mse: 141.8371 - val_loss: 2168.3220 - val_mse: 2168.3220\n",
            "Epoch 38/100\n",
            "289/289 [==============================] - 115s 398ms/step - loss: 139.4898 - mse: 139.4898 - val_loss: 1975.3544 - val_mse: 1975.3544\n",
            "Epoch 39/100\n",
            "289/289 [==============================] - 120s 413ms/step - loss: 136.1045 - mse: 136.1045 - val_loss: 2137.3274 - val_mse: 2137.3274\n",
            "Epoch 40/100\n",
            "289/289 [==============================] - 112s 389ms/step - loss: 135.2570 - mse: 135.2570 - val_loss: 1930.5737 - val_mse: 1930.5737\n",
            "Epoch 41/100\n",
            "289/289 [==============================] - 113s 390ms/step - loss: 130.8203 - mse: 130.8203 - val_loss: 1917.4969 - val_mse: 1917.4969\n",
            "Epoch 42/100\n",
            "289/289 [==============================] - 112s 386ms/step - loss: 131.3001 - mse: 131.3001 - val_loss: 1999.3103 - val_mse: 1999.3103\n",
            "Epoch 43/100\n",
            "289/289 [==============================] - 115s 398ms/step - loss: 130.2753 - mse: 130.2753 - val_loss: 2195.3728 - val_mse: 2195.3728\n",
            "Epoch 44/100\n",
            "289/289 [==============================] - 111s 386ms/step - loss: 130.3957 - mse: 130.3957 - val_loss: 2139.8169 - val_mse: 2139.8169\n",
            "Epoch 45/100\n",
            "289/289 [==============================] - 111s 385ms/step - loss: 126.8219 - mse: 126.8219 - val_loss: 2139.3965 - val_mse: 2139.3965\n",
            "Epoch 46/100\n",
            "289/289 [==============================] - 115s 397ms/step - loss: 128.1400 - mse: 128.1400 - val_loss: 2199.2781 - val_mse: 2199.2781\n",
            "Epoch 47/100\n",
            "289/289 [==============================] - 116s 402ms/step - loss: 126.1477 - mse: 126.1477 - val_loss: 1879.4830 - val_mse: 1879.4830\n",
            "Epoch 48/100\n",
            "289/289 [==============================] - 113s 392ms/step - loss: 128.3407 - mse: 128.3407 - val_loss: 1960.5645 - val_mse: 1960.5645\n",
            "Epoch 49/100\n",
            "289/289 [==============================] - 115s 397ms/step - loss: 123.1863 - mse: 123.1863 - val_loss: 2398.8416 - val_mse: 2398.8416\n",
            "Epoch 50/100\n",
            "289/289 [==============================] - 114s 394ms/step - loss: 121.9007 - mse: 121.9007 - val_loss: 1989.0719 - val_mse: 1989.0719\n",
            "Epoch 51/100\n",
            "289/289 [==============================] - 114s 395ms/step - loss: 119.9658 - mse: 119.9658 - val_loss: 2116.8884 - val_mse: 2116.8884\n",
            "Epoch 52/100\n",
            "289/289 [==============================] - 115s 398ms/step - loss: 120.0970 - mse: 120.0970 - val_loss: 1832.8037 - val_mse: 1832.8037\n",
            "Epoch 53/100\n",
            "289/289 [==============================] - 113s 390ms/step - loss: 118.5176 - mse: 118.5176 - val_loss: 2125.3137 - val_mse: 2125.3137\n",
            "Epoch 54/100\n",
            "289/289 [==============================] - 112s 388ms/step - loss: 120.2743 - mse: 120.2743 - val_loss: 2206.4104 - val_mse: 2206.4104\n",
            "Epoch 55/100\n",
            "289/289 [==============================] - 113s 392ms/step - loss: 119.6988 - mse: 119.6988 - val_loss: 2015.2190 - val_mse: 2015.2190\n",
            "Epoch 56/100\n",
            "289/289 [==============================] - 113s 393ms/step - loss: 117.0704 - mse: 117.0704 - val_loss: 2078.3545 - val_mse: 2078.3545\n",
            "Epoch 57/100\n",
            "289/289 [==============================] - 112s 389ms/step - loss: 117.8157 - mse: 117.8157 - val_loss: 2193.8042 - val_mse: 2193.8042\n",
            "Epoch 58/100\n",
            "289/289 [==============================] - 113s 391ms/step - loss: 115.8757 - mse: 115.8757 - val_loss: 2213.0422 - val_mse: 2213.0422\n",
            "Epoch 59/100\n",
            "289/289 [==============================] - 115s 397ms/step - loss: 115.2872 - mse: 115.2872 - val_loss: 2471.5676 - val_mse: 2471.5676\n",
            "Epoch 60/100\n",
            "289/289 [==============================] - 124s 429ms/step - loss: 113.4285 - mse: 113.4285 - val_loss: 2145.7769 - val_mse: 2145.7769\n",
            "Epoch 61/100\n",
            "289/289 [==============================] - 115s 399ms/step - loss: 114.8964 - mse: 114.8964 - val_loss: 2270.7437 - val_mse: 2270.7437\n",
            "Epoch 62/100\n",
            "289/289 [==============================] - 115s 400ms/step - loss: 115.3999 - mse: 115.3999 - val_loss: 2289.7742 - val_mse: 2289.7742\n",
            "Epoch 63/100\n",
            "289/289 [==============================] - 118s 409ms/step - loss: 112.7809 - mse: 112.7809 - val_loss: 2303.5520 - val_mse: 2303.5520\n",
            "Epoch 64/100\n",
            "289/289 [==============================] - 114s 393ms/step - loss: 111.3764 - mse: 111.3764 - val_loss: 2267.2825 - val_mse: 2267.2825\n",
            "Epoch 65/100\n",
            "289/289 [==============================] - 112s 388ms/step - loss: 115.8011 - mse: 115.8011 - val_loss: 2221.6809 - val_mse: 2221.6809\n",
            "Epoch 66/100\n",
            "289/289 [==============================] - 113s 393ms/step - loss: 111.5607 - mse: 111.5607 - val_loss: 2371.4758 - val_mse: 2371.4758\n",
            "Epoch 67/100\n",
            "289/289 [==============================] - 114s 395ms/step - loss: 109.4651 - mse: 109.4651 - val_loss: 2320.4463 - val_mse: 2320.4463\n",
            "Epoch 68/100\n",
            "289/289 [==============================] - 120s 415ms/step - loss: 109.7548 - mse: 109.7548 - val_loss: 2539.7625 - val_mse: 2539.7625\n",
            "Epoch 69/100\n",
            "289/289 [==============================] - 113s 393ms/step - loss: 109.7556 - mse: 109.7556 - val_loss: 2180.3391 - val_mse: 2180.3391\n",
            "Epoch 70/100\n",
            "289/289 [==============================] - 114s 396ms/step - loss: 108.7068 - mse: 108.7068 - val_loss: 2403.0627 - val_mse: 2403.0627\n",
            "Epoch 71/100\n",
            "289/289 [==============================] - 114s 393ms/step - loss: 108.0493 - mse: 108.0493 - val_loss: 2508.6838 - val_mse: 2508.6838\n",
            "Epoch 72/100\n",
            "289/289 [==============================] - 113s 392ms/step - loss: 107.1263 - mse: 107.1263 - val_loss: 2273.2336 - val_mse: 2273.2336\n",
            "Epoch 73/100\n",
            "289/289 [==============================] - 112s 389ms/step - loss: 107.9026 - mse: 107.9026 - val_loss: 2292.7686 - val_mse: 2292.7686\n",
            "Epoch 74/100\n",
            "289/289 [==============================] - 123s 425ms/step - loss: 105.9905 - mse: 105.9905 - val_loss: 2531.9714 - val_mse: 2531.9714\n",
            "Epoch 75/100\n",
            "289/289 [==============================] - 116s 402ms/step - loss: 107.4723 - mse: 107.4723 - val_loss: 2258.6331 - val_mse: 2258.6331\n",
            "Epoch 76/100\n",
            "289/289 [==============================] - 112s 388ms/step - loss: 105.4235 - mse: 105.4235 - val_loss: 2244.4050 - val_mse: 2244.4050\n",
            "Epoch 77/100\n",
            "289/289 [==============================] - 113s 393ms/step - loss: 109.8611 - mse: 109.8611 - val_loss: 2372.3057 - val_mse: 2372.3057\n",
            "Epoch 78/100\n",
            "289/289 [==============================] - 120s 415ms/step - loss: 107.4239 - mse: 107.4239 - val_loss: 2319.0625 - val_mse: 2319.0625\n",
            "Epoch 79/100\n",
            "289/289 [==============================] - 116s 403ms/step - loss: 104.9754 - mse: 104.9754 - val_loss: 2300.5183 - val_mse: 2300.5183\n",
            "Epoch 80/100\n",
            "289/289 [==============================] - 114s 393ms/step - loss: 103.8708 - mse: 103.8708 - val_loss: 2508.2949 - val_mse: 2508.2949\n",
            "Epoch 81/100\n",
            "289/289 [==============================] - 119s 413ms/step - loss: 105.6883 - mse: 105.6883 - val_loss: 2284.9788 - val_mse: 2284.9788\n",
            "Epoch 82/100\n",
            "289/289 [==============================] - 112s 388ms/step - loss: 101.9555 - mse: 101.9555 - val_loss: 2740.6018 - val_mse: 2740.6018\n",
            "Epoch 83/100\n",
            "289/289 [==============================] - 115s 397ms/step - loss: 105.9839 - mse: 105.9839 - val_loss: 2153.5181 - val_mse: 2153.5181\n",
            "Epoch 84/100\n",
            "289/289 [==============================] - 113s 392ms/step - loss: 101.3030 - mse: 101.3030 - val_loss: 2586.5408 - val_mse: 2586.5408\n",
            "Epoch 85/100\n",
            "289/289 [==============================] - 120s 416ms/step - loss: 101.8753 - mse: 101.8753 - val_loss: 2569.0898 - val_mse: 2569.0898\n",
            "Epoch 86/100\n",
            "289/289 [==============================] - 117s 404ms/step - loss: 103.2668 - mse: 103.2668 - val_loss: 2271.5989 - val_mse: 2271.5989\n",
            "Epoch 87/100\n",
            "289/289 [==============================] - 119s 412ms/step - loss: 103.4303 - mse: 103.4303 - val_loss: 2346.8623 - val_mse: 2346.8623\n",
            "Epoch 88/100\n",
            "289/289 [==============================] - 115s 398ms/step - loss: 101.3767 - mse: 101.3767 - val_loss: 2382.2915 - val_mse: 2382.2915\n",
            "Epoch 89/100\n",
            "289/289 [==============================] - 119s 410ms/step - loss: 100.8923 - mse: 100.8923 - val_loss: 2304.3176 - val_mse: 2304.3176\n",
            "Epoch 90/100\n",
            "289/289 [==============================] - 120s 415ms/step - loss: 101.7956 - mse: 101.7956 - val_loss: 2268.4685 - val_mse: 2268.4685\n",
            "Epoch 91/100\n",
            "289/289 [==============================] - 119s 412ms/step - loss: 97.7288 - mse: 97.7288 - val_loss: 2445.0168 - val_mse: 2445.0168\n",
            "Epoch 92/100\n",
            "289/289 [==============================] - 121s 419ms/step - loss: 101.1098 - mse: 101.1098 - val_loss: 2719.6287 - val_mse: 2719.6287\n",
            "Epoch 93/100\n",
            "289/289 [==============================] - 115s 399ms/step - loss: 99.0861 - mse: 99.0861 - val_loss: 2293.6011 - val_mse: 2293.6011\n",
            "Epoch 94/100\n",
            "289/289 [==============================] - 115s 398ms/step - loss: 97.8603 - mse: 97.8603 - val_loss: 2307.1174 - val_mse: 2307.1174\n",
            "Epoch 95/100\n",
            "289/289 [==============================] - 117s 405ms/step - loss: 99.5901 - mse: 99.5901 - val_loss: 2431.5464 - val_mse: 2431.5464\n",
            "Epoch 96/100\n",
            "289/289 [==============================] - 113s 392ms/step - loss: 96.4436 - mse: 96.4436 - val_loss: 2340.2832 - val_mse: 2340.2832\n",
            "Epoch 97/100\n",
            "289/289 [==============================] - 117s 404ms/step - loss: 97.5911 - mse: 97.5911 - val_loss: 2075.0903 - val_mse: 2075.0903\n",
            "Epoch 98/100\n",
            "289/289 [==============================] - 121s 418ms/step - loss: 97.9925 - mse: 97.9925 - val_loss: 2259.9387 - val_mse: 2259.9387\n",
            "Epoch 99/100\n",
            "289/289 [==============================] - 113s 393ms/step - loss: 97.7004 - mse: 97.7004 - val_loss: 2650.3369 - val_mse: 2650.3369\n",
            "Epoch 100/100\n",
            "289/289 [==============================] - 113s 391ms/step - loss: 94.8291 - mse: 94.8291 - val_loss: 2424.3870 - val_mse: 2424.3870\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d983f0f6800>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "model.fit(x_train, y_train, epochs=100, batch_size=128, validation_split=0.1, verbose=1, callbacks=[history])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Ut7_JWfZS1zd"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(y_true, y_pred):\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    print(f'RMSE: {rmse:.0f}')\n",
        "\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    print(f'MAE: {mae:.0f}')\n",
        "\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    print(f'R² Score: {r2:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "T2OCiqc1S4ia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69c1fbe0-404b-40a6-cee2-2029c3eec49b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1282/1282 [==============================] - 59s 45ms/step\n",
            "Training Set Performance:\n",
            "RMSE: 16\n",
            "MAE: 7\n",
            "R² Score: 0.9218\n"
          ]
        }
      ],
      "source": [
        "y_train_pred = model.predict(x_train).flatten()\n",
        "\n",
        "print(\"Training Set Performance:\")\n",
        "evaluate_model(y_train, y_train_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Qv0wyf4pS79b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c5b285c-ff26-4ff7-c2e9-3f85fb3e0fc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 41ms/step\n",
            "\n",
            "Test Set Performance:\n",
            "RMSE: 42\n",
            "MAE: 30\n",
            "R² Score: 0.3864\n"
          ]
        }
      ],
      "source": [
        "y_test_pred = model.predict(x_test).flatten()\n",
        "\n",
        "print(\"\\nTest Set Performance:\")\n",
        "evaluate_model(y_test, y_test_pred)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}